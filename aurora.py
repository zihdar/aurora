# -*- coding: utf-8 -*-
"""aurora.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X07u5xu1QjV-gmpARzOFwXHSO3_hqLmF
"""
pip install matplotlib
pip install streamlit
pip install numpy
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler
from imblearn.over_sampling import SMOTE

df = pd.read_csv('aurora1.csv')
df

df.info()

duplicates = df[df.duplicated()]
print("duplicate =", len(duplicates))
duplicates

df.describe(include='all')

sns.heatmap(df.isnull(), cbar=False)
plt.title("Missing Data Heatmap")
plt.show()

df.isnull().sum()

# drop missing data rows of SatisfactionScore and reset index
df.dropna(subset=['SatisfactionScore'], inplace=True)
df.reset_index(drop=True, inplace=True)
df

#cleaning the column UnitPrice by calculating missing data
df['UnitPrice'] = df.apply(lambda row: row['Revenue'] / row['Units'] if row['UnitPrice'] == 'unknown' or 'NaN' else row['UnitPrice'], axis=1).round(2)
df

duplicates = df[df.duplicated()]
print("duplicate =", len(duplicates))
duplicates

#cleaning the Revenue and Revenue_After_Discount
df['Revenue'] = df['Revenue'].round(2)
df['Revenue_After_Discount'] = df['Revenue_After_Discount'].round(2)
df

#cleaning CustomerType
df['CustomerType'] = df['CustomerType'].replace('123', np.nan)
df



#check univariants after cleaning
df.describe(include='all')

#check missing data after cleaning
df.isnull().sum()

print(df['Returned'].value_counts(normalize=True))

sns.countplot(data=df, x='Returned')
plt.title("Returned Class Distribution")
plt.show()

print(df['SatisfactionScore'].value_counts(normalize=True)*100)

sns.countplot(data=df, x='SatisfactionScore')
plt.title("SatisfactionScore Class Distribution")
plt.show()

revenue_return = df.groupby('Returned')['Revenue'].sum()
plt.figure(figsize=(8, 6))
plt.bar(revenue_return.index, revenue_return.values)
plt.xlabel('Returned')
plt.ylabel('Revenue')
plt.title('Revenue by Returned')
plt.show()
revenue_return

#Drop Returned Column
df.drop('Returned', axis=1, inplace=True)

df

df.duplicated().sum()

#shifting Satisfactionscore to the end of the df
col=df.pop('SatisfactionScore')
df['SatisfactionScore']=col
df

df["SatisfactionScore"].value_counts().plot(kind="pie", autopct = "%1.2f")
plt.title("Distribution of SatisfactionScore")
plt.show()



#Revenue per product
revenue_per_product = df.groupby('Product')['Revenue'].sum().sort_values(ascending=False)
print("Total Revenue per Product:")
print(revenue_per_product)

plt.figure(figsize=(10, 8))
plt.pie(revenue_per_product, labels=revenue_per_product.index, autopct='%1.1f%%', startangle=90)
plt.title("Revenue Distribution by Product")
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

revenue_per_CustomerType = df.groupby('CustomerType')['Revenue'].sum().sort_values(ascending=False)
print("Total Revenue per CustomerType:")
print(revenue_per_CustomerType)

plt.figure(figsize=(10, 8))
plt.pie(revenue_per_CustomerType, labels=revenue_per_CustomerType.index, autopct='%1.1f%%', startangle=90)
plt.title("Revenue Distribution by CustomerType")
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

#obtain each product count per cusomer type
product_counts_per_customer_type = df.groupby('CustomerType')['Product'].value_counts()
product_customer = df.pivot_table(index='CustomerType', columns='Product', values='OrderID', aggfunc='count', fill_value=0)
print("Product Count per Customer Type (Pivot Table):")
display(product_customer)

# Cleaning : change products names to Lower case and removing free spaces
df['Product'] = df['Product'].str.lower().str.strip()
df

#obtain each product count per cusomer type after cleaning
product_counts_per_customer_type = df.groupby('CustomerType')['Product'].value_counts()
product_customer_pivot = df.pivot_table(index='CustomerType', columns='Product', values='OrderID', aggfunc='count', fill_value=0)
print("Product Count per Customer Type (Pivot Table):")
display(product_customer_pivot)

for customer_type in product_customer_pivot.index:
    plt.figure(figsize=(8, 8))
    data_to_plot = product_customer_pivot.loc[customer_type]
    plt.pie(data_to_plot, labels=data_to_plot.index, autopct='%1.1f%%', startangle=90)
    plt.title(f"Product Distribution for Customer Type: {customer_type}")
    plt.axis('equal')
    plt.show()

df

#Check Out Liers
numerical_cols = df.select_dtypes(include=np.number).columns

for col in numerical_cols:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[col])
    plt.title(f'Box plot of {col}')
    plt.show()

#Show outliers values
for col in numerical_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f'Outliers in {col}:')
    display(outliers)

# Change negative UnitPrice values to absolute values
df['UnitPrice'] = df['UnitPrice'].abs()

# Change negative Units values to absolute values
df['Units'] = df['Units'].abs()

#Check Out Liers after correction
numerical_cols = df.select_dtypes(include=np.number).columns

for col in numerical_cols:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[col])
    plt.title(f'Box plot of {col}')
    plt.show()

#Show outliers values after correction
for col in numerical_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f'Outliers in {col}:')
    display(outliers)

#Revenue per Region
revenue_per_Region = df.groupby('Region')['Revenue'].sum().sort_values(ascending=False)
print("Total Revenue per Region:")
print(revenue_per_Region)

#Revenue per Region Pir chart
plt.figure(figsize=(10, 8))
plt.pie(revenue_per_Region, labels=revenue_per_Region.index, autopct='%1.1f%%', startangle=90)
plt.title("Revenue Distribution by Region")
plt.axis('equal')
plt.show()

#Revenue per Sales Person
revenue_per_Salesperson = df.groupby('Salesperson')['Revenue'].sum().sort_values(ascending=False)
print("Total Revenue per Salesperson:")
print(revenue_per_Salesperson)

#Revenue per Sales Person Pir chart
plt.figure(figsize=(10, 8))
plt.pie(revenue_per_Salesperson, labels=revenue_per_Salesperson.index, autopct='%1.1f%%', startangle=90)
plt.title("Revenue Distribution by Salesperson")
plt.axis('equal')
plt.show()

#cleaning Sales Person
df['Salesperson'] = df['Salesperson'].replace('unknown', np.nan)

#Revenue per Sales Person
revenue_per_Salesperson = df.groupby('Salesperson')['Revenue'].sum().sort_values(ascending=False)
plt.figure(figsize=(10, 8))
plt.pie(revenue_per_Salesperson, labels=revenue_per_Salesperson.index, autopct='%1.1f%%', startangle=90)
plt.title("Revenue Distribution by Salesperson")
plt.axis('equal')
plt.show()

df

# Find locations of 'unknown' in all items in the dataframe
unknown_locations = []
for col in df.columns:
    for index, value in df[col].items():
        if isinstance(value, str) and 'unknown' in value:
            unknown_locations.append({'column': col, 'row_index': index, 'value': value})

if unknown_locations:
    print("Locations of 'unknown' in the dataframe:")
    for loc in unknown_locations:
        print(f"Column: {loc['column']}, Row Index: {loc['row_index']}, Value: {loc['value']}")
else:
    print("No 'unknown' values found in the dataframe.")

#check missing data after cleaning
missing_data = df.isnull().sum()
plt.figure(figsize=(12, 10))
missing_data.plot(kind='bar')
plt.xlabel('Item Name')
plt.ylabel('missing_data')
plt.title('missing_data_per_Item')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

df.describe(include='all')

# Convert the 'Date' column to datetime objects
#df['Date'] = pd.to_datetime(df['Date'])

# Group by Date and calculate the sum of Revenue
revenue_per_date = df.groupby('Date')['Revenue'].sum().sort_values(ascending=0)

# Create a bar chart
plt.figure(figsize=(12, 10))
revenue_per_date.plot(kind='bar')
plt.xlabel('Date')
plt.ylabel('Revenue')
plt.title('Revenue per Date')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Calculate the average satisfaction score per customer type
average_satisfaction_per_customer_type = df.groupby('CustomerType')['SatisfactionScore'].mean()

print("Average Satisfaction Score per Customer Type:")
display(average_satisfaction_per_customer_type)

# Calculate the average satisfaction score per Sales Person type
average_satisfaction_per_Salesperson = df.groupby('Salesperson')['SatisfactionScore'].mean().sort_values(ascending=0)

print("Average Satisfaction Score per Salesperson Type:")
display(average_satisfaction_per_Salesperson)

# Calculate the Total Revenue per Sales Person type
Revenue_per_Salesperson = df.groupby('Salesperson')['Revenue'].sum().sort_values(ascending=0)

print("Total revenue Salesperson:")
Revenue_per_Salesperson

# Combine the two series into a single DataFrame for plotting
salesperson_analysis = pd.DataFrame({
    'Average Satisfaction Score': average_satisfaction_per_Salesperson,
    'Total Revenue': Revenue_per_Salesperson
})

# Create a scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(data=salesperson_analysis, x='Average Satisfaction Score', y='Total Revenue')
plt.title('Average Satisfaction Score vs. Total Revenue per Salesperson')
plt.xlabel('Average Satisfaction Score')
plt.ylabel('Total Revenue')

# Add labels for each salesperson
for i, salesperson in enumerate(salesperson_analysis.index):
    plt.text(salesperson_analysis['Average Satisfaction Score'][i], salesperson_analysis['Total Revenue'][i], salesperson)

plt.grid(True)
plt.show()

#  relationship between average satisfaction, total revenue, and product for each salesperson

# 1- Group the product by salesperson

salesperson_product = df.groupby(['Salesperson', 'Product']).agg(
    Average_Satisfaction_Score=('SatisfactionScore', 'mean'),
    Total_Revenue=('Revenue', 'sum')
).reset_index()

# 2- unique products
products = salesperson_product['Product'].unique()

# 3- scatter plot per product
for product in products:
    product_data = salesperson_product[salesperson_product['Product'] == product]

    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=product_data, x='Average_Satisfaction_Score', y='Total_Revenue', s=100) # s is for marker size
    plt.title(f'Average Satisfaction Score vs. Total Revenue for {product} per Salesperson')
    plt.xlabel('Average Satisfaction Score')
    plt.ylabel('Total Revenue')

    # Add labels for each salesperson
    for index, row in product_data.iterrows():
        plt.text(row['Average_Satisfaction_Score'], row['Total_Revenue'], row['Salesperson'], fontsize=9)

    plt.grid(True)
    plt.show()

# line plot between Avrage_satisfaction_score and total_revenue and show name of each sales person on the plot
plt.figure(figsize=(10, 6))
sns.lineplot(data=salesperson_analysis, x='Average Satisfaction Score', y='Total Revenue')
plt.title('Average Satisfaction Score vs. Total Revenue per Salesperson')
plt.xlabel('Average Satisfaction Score')
plt.ylabel('Total Revenue')

# Add labels for each salesperson
for i, salesperson in enumerate(salesperson_analysis.index):
    plt.text(salesperson_analysis['Average Satisfaction Score'][i], salesperson_analysis['Total Revenue'][i], salesperson)

plt.grid(True)
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %pip install category-encoders

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler
from category_encoders import BinaryEncoder

df

x = df.drop('SatisfactionScore', axis=1)
y =df["SatisfactionScore"]

x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)

x_train

#shape of result  df
x_train.shape, x_test.shape, y_train.shape, y_test.shape

sim_imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
knn_imp = KNNImputer(n_neighbors=5)

sim_imp

knn_imp

#show missing data in x_train and x_test
x_train.isnull().sum()



#Draw a bar chart of the missing data distribution
plt.figure(figsize=(12, 10))
x_train.isnull().sum().plot(kind='bar')
plt.xlabel('Item Name')
plt.ylabel('missing_data')
plt.title('missing_data_per_Item')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

#show x_test missing data
x_test.isnull().sum()

#apply simple imputer on catigorical missing data
x_train[['CustomerType']] = sim_imp.fit_transform(x_train[['CustomerType']])
x_test[['CustomerType']] = sim_imp.transform(x_test[['CustomerType']])
x_train[['Salesperson']] = sim_imp.fit_transform(x_train[['Salesperson']])
x_test[['Salesperson']] = sim_imp.transform(x_test[['Salesperson']])
x_train[['Region']] = sim_imp.fit_transform(x_train[['Region']])
x_test[['Region']] = sim_imp.transform(x_test[['Region']])
#apply knn imputer on the numerical missing data
x_train[['ShippingCost']] = knn_imp.fit_transform(x_train[['ShippingCost']])
x_test[['ShippingCost']] = knn_imp.transform(x_test[['ShippingCost']])

#show missing data in x_train after apply
x_train.isnull().sum()

#Draw a bar chart of the missing data distribution after applying the imputers
plt.figure(figsize=(12, 10))
x_train.isnull().sum().plot(kind='bar')
plt.xlabel('Item Name')
plt.ylabel('missing_data')
plt.title('missing_data_per_Item')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(sparse_output=False, drop="first")

#get x_train catigorical data columns names
cat_cols = x_train.select_dtypes(include='object').columns
cat_cols

#date column to datete format
x_train['Date'] = pd.to_datetime(x_train['Date'])
x_test['Date'] = pd.to_datetime(x_test['Date'])

#Encoding x_train catigorical data
x_train_cat_encoded = ohe.fit_transform(x_train[['Region', 'Salesperson', 'Product', 'CustomerType', 'Priority',
       'PaymentMethod', 'Warehouse', 'ShippingMethod', 'Referral']])
#encoded x train from aaray to df
x_train_cat_encoded_df = pd.DataFrame(x_train_cat_encoded, columns=ohe.get_feature_names_out(['Region', 'Salesperson', 'Product', 'CustomerType', 'Priority',
       'PaymentMethod', 'Warehouse', 'ShippingMethod', 'Referral']),index=x_train.index)
x_train_cat_encoded_df

#Encoding x_test catigorical data
x_test_cat_encoded = ohe.transform(x_test[['Region', 'Salesperson', 'Product', 'CustomerType', 'Priority',
       'PaymentMethod', 'Warehouse', 'ShippingMethod', 'Referral']])
#encoded x test from array to df
x_test_cat_encoded_df = pd.DataFrame(x_test_cat_encoded, columns=ohe.get_feature_names_out(['Region', 'Salesperson', 'Product', 'CustomerType', 'Priority',
       'PaymentMethod', 'Warehouse', 'ShippingMethod', 'Referral']),index=x_test.index)
x_test_cat_encoded_df

#update the x_train
#x_train drop catigorical columns
x_train.drop(columns=['Region', 'Salesperson', 'Product', 'CustomerType', 'Priority',
       'PaymentMethod', 'Warehouse', 'ShippingMethod', 'Referral'], inplace=True)
#x_train update adding encoded columns
x_train = pd.concat([x_train, x_train_cat_encoded_df], axis=1)

x_train

#update the x_test
#x_test drop catigorical columns
x_test.drop(columns=['Region', 'Salesperson', 'Product', 'CustomerType', 'Priority',
       'PaymentMethod', 'Warehouse', 'ShippingMethod', 'Referral'], inplace=True)
#x_test update adding encoded columns
x_test = pd.concat([x_test, x_test_cat_encoded_df], axis=1)

x_test

#x_train drop order id
x_train.drop(columns=['OrderID'], inplace=True)
x_train

#x_test drop ordr id
x_test.drop(columns=['OrderID'], inplace=True)
x_test

scaler = StandardScaler()
xxscaler = MinMaxScaler()

xxscaler

#scaling x_train numerical columns
x_train[['Units','Revenue','Revenue_After_Discount', 'ShippingCost', 'UnitPrice']] = xxscaler.fit_transform(x_train[['Units','Revenue','Revenue_After_Discount', 'ShippingCost', 'UnitPrice']])
x_train

xxscaler

#scaling x_test numerical columns
x_test[['Units','Revenue','Revenue_After_Discount', 'ShippingCost', 'UnitPrice']] = xxscaler.transform(x_test[['Units','Revenue','Revenue_After_Discount', 'ShippingCost', 'UnitPrice']])
x_test

y_train.value_counts()
#balanced data

y_train.value_counts(normalize=True) *100

y_test.value_counts()
#balanced data

y_test.value_counts(normalize=True) *100
